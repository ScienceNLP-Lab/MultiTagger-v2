#!/bin/bash


# Fine-tuning using undersampled data, verbalized features, and unsupervised contrastive loss
python train.py --label_file="data/labels/stratified_data.csv" --data_file="data/pubmed/pubmed_data.csv" --train_val_test="train" --verbalize="True" --verbalize_missing="" --remove_feature="" --use_gpu=1 --gpu_device=0 --save=1 --bert_model_name="microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext" --bert_dropout=0.1 --batch_size=16 --eval_batch_size=16 --eval_steps=3 --max_epoch=15 --weight_decay=0 --bert_weight_decay=0 --learning_rate=1e-2 --bert_learning_rate=1e-4 --lr_scheduler=True --early_stopping=2 --undersampling=0.2 --undersampling_min_thresh=700 --contrastive_loss="unsup" --cl_temp=0.05 --cl_alpha=0.4

# Evaluation of using undersampled data, verbalized features, and unsupervised contrastive loss
# You need to run an evaluation script on validation subset before test subset as optimal thresholds need to be calculated
python train.py --label_file="data/labels/stratified_data.csv" --data_file="data/pubmed/pubmed_data.csv" --train_val_test="val" --verbalize="True" --verbalize_missing="" --remove_feature="" --use_gpu=1 --gpu_device=0 --save=1 --bert_model_name="microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext" --bert_dropout=0.1 --batch_size=16 --eval_batch_size=16 --eval_steps=3 --max_epoch=15 --weight_decay=0 --bert_weight_decay=0 --learning_rate=1e-2 --bert_learning_rate=1e-4 --lr_scheduler=True --early_stopping=2 --undersampling=0.2 --undersampling_min_thresh=700 --contrastive_loss="unsup" --cl_temp=0.05 --cl_alpha=0.4 --align_for_comparison_with_v1="True" --checkpoint="path/2/directory/containing/mdl"

python train.py --label_file="data/labels/stratified_data.csv" --data_file="data/pubmed/pubmed_data.csv" --train_val_test="test" --verbalize="True" --verbalize_missing="" --remove_feature="" --use_gpu=1 --gpu_device=0 --save=1 --bert_model_name="microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext" --bert_dropout=0.1 --batch_size=16 --eval_batch_size=16 --eval_steps=3 --max_epoch=15 --weight_decay=0 --bert_weight_decay=0 --learning_rate=1e-2 --bert_learning_rate=1e-4 --lr_scheduler=True --early_stopping=2 --undersampling=0.2 --undersampling_min_thresh=700 --contrastive_loss="unsup" --cl_temp=0.05 --cl_alpha=0.4 --align_for_comparison_with_v1="True" --checkpoint="path/2/directory/containing/mdl"
